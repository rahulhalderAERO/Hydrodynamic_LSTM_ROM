{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGcIYU0QBXg2SDdl88iw37",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulhalderAERO/Hydrodynamic_LSTM_ROM/blob/main/Hydrodynamic_PINN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LSTM-PINN algorithms introduces the loss function computed from the discretized governing equation.The Governing Equation is the rigid body dynamic Equation as $M\\ddot{x}  = F$\n"
      ],
      "metadata": {
        "id": "MpQpEmnmlm3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import time\n",
        "start_time = time.time()\n",
        "Ext_Col = 6\n",
        "test_step = 25"
      ],
      "metadata": {
        "id": "3tzj1mi7mm_v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Training and Test Data"
      ],
      "metadata": {
        "id": "AKLqnQjX99GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Output_Train = pd.read_csv(\"box_smooth_Dis.csv\",skiprows = None , header = None )\n",
        "Input_Train = pd.read_csv(\"Test_Input_Force_Only.csv\",skiprows = None , header = None )\n",
        "\n",
        "Output_Test = pd.read_csv(\"box_smooth_Dis.csv\",skiprows = None , header = None )\n",
        "Input_Test = pd.read_csv(\"Test_Input_Force_Only.csv\",skiprows = None , header = None )"
      ],
      "metadata": {
        "id": "3SeLDa2kmJhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize the input data"
      ],
      "metadata": {
        "id": "AT8SDOuh98Q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Output_array = Output_Train.values\n",
        "input_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "input_Traindata = input_scaler.fit_transform(Input_Train)\n",
        "input_Testdata = input_scaler.fit_transform(Input_Test)"
      ],
      "metadata": {
        "id": "rvwBzmODB6l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize output with zero\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3oUgqMsNCAGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_discrete = np.zeros(shape=(Output_array.shape[0],Output_array.shape[1]+Ext_Col*2))\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []"
      ],
      "metadata": {
        "id": "bhxi8qohCTsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the input train dataset with the windows of time"
      ],
      "metadata": {
        "id": "9TtLPfqsCYfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(test_step,input_Traindata.shape[0]):\n",
        "    x_train.append(input_Traindata[i-test_step:i,0].reshape(-1,1))\n",
        "x_train_mid = np.array(x_train)\n",
        "x_train = []\n",
        "\n",
        "for j in range(2,4):\n",
        "    for i in range(test_step,input_Traindata.shape[0]):\n",
        "        x_train.append(input_Traindata[i-test_step:i,j].reshape(-1,1))\n",
        "    x_train_mid1 = np.array(x_train)\n",
        "    x_train = []\n",
        "    x_train_final = np.concatenate((x_train_mid,x_train_mid1),axis = 2) \n",
        "    x_train_mid = x_train_final\n",
        "    \n",
        "x_train = x_train_final"
      ],
      "metadata": {
        "id": "z4aP40vgCYGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the input test dataset with the windows of time\n"
      ],
      "metadata": {
        "id": "tX7F5O5-C5lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(test_step,input_Testdata.shape[0]):\n",
        "    x_test.append(input_Testdata[i-test_step:i,0].reshape(-1,1))\n",
        "x_test_mid = np.array(x_test)\n",
        "x_test = []\n",
        "\n",
        "for j in range(2,4):\n",
        "    for i in range(test_step,input_Testdata.shape[0]):\n",
        "        x_test.append(input_Testdata[i-test_step:i,j].reshape(-1,1))\n",
        "    x_test_mid1 = np.array(x_test)\n",
        "    x_test = []\n",
        "    x_test_final = np.concatenate((x_test_mid,x_test_mid1),axis = 2) \n",
        "    x_test_mid = x_test_final\n",
        "    \n",
        "x_test = x_test_final"
      ],
      "metadata": {
        "id": "oSj1wBxpC-sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the output dataset with the windows of time"
      ],
      "metadata": {
        "id": "DLLFt0xsDEob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(Ext_Col):\n",
        "    output_discrete[:,3*(j)] = Output_array[:,j]\n",
        "    output_discrete[1:,3*(j)+1] = Output_array[:-1,j]\n",
        "    output_discrete[2:,3*(j)+2] = Output_array[:-2:,j]\n",
        "output_final =  np.concatenate((output_discrete,input_Traindata[:,1:4]),axis=1)\n",
        "\n",
        "\n",
        "output_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "output_Traindata = output_scaler.fit_transform(output_final)\n",
        "\n",
        "\n",
        "y_train = output_Traindata[test_step:len(output_final)]"
      ],
      "metadata": {
        "id": "DDFl7ckMKwka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take percentage of data"
      ],
      "metadata": {
        "id": "Q5EjtWJWK2aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list=[]\n",
        "for i in range(1):\n",
        "    r=random.randint(1,y_train.shape[0]-1)\n",
        "    if r not in list: list.append(r)\n",
        "    list_array = np.array(list)\n",
        "\n",
        "\n",
        "for k in range(len(list_array)):\n",
        "    val_row = list_array[k]\n",
        "    y_train[val_row,:-3] = 0"
      ],
      "metadata": {
        "id": "ryA8qLDbK8B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Model\n"
      ],
      "metadata": {
        "id": "JVILuKUXLBIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(LSTM(units = 50,return_sequences = True, input_shape = (x_train.shape[1], x_train.shape[2])))    \n",
        "model.add(LSTM(units =50,return_sequences = True))\n",
        "model.add(LSTM(units = 50))\n",
        "model.add(Dense(units = 21))"
      ],
      "metadata": {
        "id": "0L2YplZVLArN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and prediction Phase"
      ],
      "metadata": {
        "id": "h64KTwg9LTrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "model.compile(optimizer = 'adam' , loss = PINN_LOSS)\n",
        "history = model.fit(x_train,y_train, epochs = epochs , batch_size = 25)\n",
        "A = history.history['loss']\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "predicted_y = (model.predict(x_train))\n",
        "y_pred_trainset_inv = output_scaler.inverse_transform(predicted_y)"
      ],
      "metadata": {
        "id": "WkxHSRSBLPNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot"
      ],
      "metadata": {
        "id": "xnOnPbTqL_-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(0,len(y_train)),Output_array[test_step:,1],label='Actual')\n",
        "plt.plot(np.arange(0,len(y_train)),y_pred_trainset_inv[:,3] , label ='Predicted')"
      ],
      "metadata": {
        "id": "O4g40vTLL_lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KG-bj0gWBjrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZJP_gSsIlmLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l4vKwJEtjxJy"
      }
    }
  ]
}