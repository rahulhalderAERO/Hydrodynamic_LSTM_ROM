{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulhalderAERO/Hydrodynamic_LSTM_ROM/blob/main/Hydrodynamic_DEIM_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m_7TuutCPG3_"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "from keras import backend as K\n",
        "import time\n",
        "import tensorflow as tf\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-puXgPnKl_Z"
      },
      "source": [
        "Import input and Output Data. The input data consists of the DEIM control point elevation $\\Delta {h}$ values. The output values are the box responses in surge, plunge and pitch directions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TKH0WbJIKlSq"
      },
      "outputs": [],
      "source": [
        "output_data = pd.read_csv(\"https://raw.githubusercontent.com/rahulhalderAERO/Hydrodynamic_LSTM_ROM/main/DEIM_LSTM_Data/box_training_new_T102.csv\",skiprows = None , header = None )\n",
        "input_data = pd.read_csv(\"https://raw.githubusercontent.com/rahulhalderAERO/Hydrodynamic_LSTM_ROM/main/DEIM_LSTM_Data/Height_training_New_T102.csv\",skiprows = None , header = None )\n",
        "output_data1 = pd.read_csv(\"https://raw.githubusercontent.com/rahulhalderAERO/Hydrodynamic_LSTM_ROM/main/DEIM_LSTM_Data/box_training_new_T103.csv\",skiprows = None , header = None )\n",
        "input_data1 = pd.read_csv(\"https://raw.githubusercontent.com/rahulhalderAERO/Hydrodynamic_LSTM_ROM/main/DEIM_LSTM_Data/Height_training_New_T103.csv\",skiprows = None , header = None )\n",
        "\n",
        "test_step = 25\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_train1 = []\n",
        "y_train1 = []\n",
        "x_train_local = []\n",
        "\n",
        "output_data = output_data.values\n",
        "input_data = input_data.values\n",
        "output_data1 = output_data1.values\n",
        "input_data1 = input_data1.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyDQeGvBMVzm"
      },
      "source": [
        "Obtain maximum values of the output files to normalize the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIoeCWUTg1x6"
      },
      "source": [
        "Adding time sequence in the input time for the training data set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5I3uUfcVhB2c"
      },
      "outputs": [],
      "source": [
        "for i in range(test_step,input_data.shape[0]):\n",
        "    x_train.append(input_data[i-test_step:i,0].reshape(-1,1))\n",
        "x_train_mid = np.array(x_train)\n",
        "x_train = []\n",
        "\n",
        "for j in range(1,31):\n",
        "    for i in range(test_step,input_data.shape[0]):\n",
        "        x_train.append(input_data[i-test_step:i,j].reshape(-1,1))\n",
        "    x_train_mid1 = np.array(x_train)\n",
        "    x_train = []\n",
        "    x_train_final = np.concatenate((x_train_mid,x_train_mid1),axis =2) \n",
        "    x_train_mid = x_train_final\n",
        "    \n",
        "x_train = x_train_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29lVVr_shZzt"
      },
      "source": [
        "Adding time sequence in the input time for the test data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WCQzodmmhIgh"
      },
      "outputs": [],
      "source": [
        "for i in range(test_step,input_data1.shape[0]):\n",
        "    x_train1.append(input_data1[i-test_step:i,0].reshape(-1,1))\n",
        "x_train1_mid = np.array(x_train1)\n",
        "x_train1 = []\n",
        "\n",
        "for j in range(1,31):\n",
        "    for i in range(test_step,input_data1.shape[0]):\n",
        "        x_train1.append(input_data1[i-test_step:i,j].reshape(-1,1))\n",
        "    x_train1_mid1 = np.array(x_train1)\n",
        "    x_train1 = []\n",
        "    x_train1_final = np.concatenate((x_train1_mid,x_train1_mid1),axis =2) \n",
        "    x_train1_mid = x_train1_final\n",
        "    \n",
        "x_train1 = x_train1_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1cIGm33hfEu"
      },
      "source": [
        "Normalize an output data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5wQkGCdshzJr"
      },
      "outputs": [],
      "source": [
        "output_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "output_data_Scaled = output_scaler.fit_transform(output_data)\n",
        "output_data_Scaled1 = output_scaler.fit_transform(output_data1)\n",
        "y_train = output_data_Scaled[test_step:len(output_data_Scaled)]\n",
        "y_train1 = output_data_Scaled1[test_step:len(output_data_Scaled1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaY3S1yaiBa9"
      },
      "source": [
        "LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4E78sULqtiKQ"
      },
      "outputs": [],
      "source": [
        "units = 50\n",
        "model = Sequential()\n",
        "epochs = 250\n",
        "# Adding the first LSTM layer\n",
        "model.add(LSTM(units = units,return_sequences = True, input_shape = (x_train.shape[1], x_train.shape[2])))    \n",
        "\n",
        "#Adding the Second LSTM layer\n",
        "model.add(LSTM(units =units,return_sequences = True ))\n",
        "\n",
        "# Adding the Fourth LSTM layer\n",
        "model.add(LSTM(units = units))\n",
        "\n",
        "#Adding the output layer\n",
        "model.add(Dense(units = 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6HQH3totqDh"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ydr3kcyt0u4",
        "outputId": "d64588eb-90a8-4e0b-f89d-ebf8fedd6403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "198/198 [==============================] - 12s 39ms/step - loss: 0.0393\n",
            "Epoch 2/250\n",
            "198/198 [==============================] - 8s 40ms/step - loss: 0.0040\n",
            "Epoch 3/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 0.0018\n",
            "Epoch 4/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 0.0015\n",
            "Epoch 5/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 0.0010\n",
            "Epoch 6/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 0.0011\n",
            "Epoch 7/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 6.6829e-04\n",
            "Epoch 8/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 4.8116e-04\n",
            "Epoch 9/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 5.7141e-04\n",
            "Epoch 10/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 7.0954e-04\n",
            "Epoch 11/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 4.9194e-04\n",
            "Epoch 12/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 4.3688e-04\n",
            "Epoch 13/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 5.2527e-04\n",
            "Epoch 14/250\n",
            "198/198 [==============================] - 5s 24ms/step - loss: 4.4647e-04\n",
            "Epoch 15/250\n",
            "198/198 [==============================] - 5s 27ms/step - loss: 3.9296e-04\n",
            "Epoch 16/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 5.5164e-04\n",
            "Epoch 17/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 6.4072e-04\n",
            "Epoch 18/250\n",
            "198/198 [==============================] - 5s 27ms/step - loss: 0.0017\n",
            "Epoch 19/250\n",
            "198/198 [==============================] - 6s 29ms/step - loss: 2.3948e-04\n",
            "Epoch 20/250\n",
            "198/198 [==============================] - 6s 29ms/step - loss: 2.2028e-04\n",
            "Epoch 21/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.4239e-04\n",
            "Epoch 22/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.1344e-04\n",
            "Epoch 23/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.6884e-04\n",
            "Epoch 24/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.8055e-04\n",
            "Epoch 25/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.9746e-04\n",
            "Epoch 26/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.3723e-04\n",
            "Epoch 27/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.5083e-04\n",
            "Epoch 28/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 5.1826e-04\n",
            "Epoch 29/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.9744e-04\n",
            "Epoch 30/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.2017e-04\n",
            "Epoch 31/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 2.0682e-04\n",
            "Epoch 32/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 5.6498e-04\n",
            "Epoch 33/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 3.7464e-04\n",
            "Epoch 34/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 2.1939e-04\n",
            "Epoch 35/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 1.4140e-04\n",
            "Epoch 36/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 2.3660e-04\n",
            "Epoch 37/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 1.8004e-04\n",
            "Epoch 38/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 1.6374e-04\n",
            "Epoch 39/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 1.8466e-04\n",
            "Epoch 40/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 2.1008e-04\n",
            "Epoch 41/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 4.0505e-04\n",
            "Epoch 42/250\n",
            "198/198 [==============================] - 5s 26ms/step - loss: 1.8730e-04\n",
            "Epoch 43/250\n",
            "198/198 [==============================] - 5s 25ms/step - loss: 6.5706e-04\n",
            "Epoch 44/250\n",
            "134/198 [===================>..........] - ETA: 1s - loss: 1.5756e-04"
          ]
        }
      ],
      "source": [
        "##Compile the LSTM\n",
        "model.compile(optimizer = 'adam' , loss = 'mse')\n",
        "history = model.fit(x_train,y_train, epochs = epochs , batch_size = 10)\n",
        "Time_taken = ((time.time() - start_time))\n",
        "#model.save(('Take2_Trainstep_{}epochs_{}variable_units_{}_time_{}.h5'.format(test_step,epochs,units,Time_taken)), include_optimizer=False)\n",
        "#A = history.history['loss']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cjdlfDNuBwG"
      },
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIlKgntLuEpF"
      },
      "outputs": [],
      "source": [
        "predicted_y = (model.predict(x_train1))\n",
        "y_pred_trainset_inv = output_scaler.inverse_transform(predicted_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHerCvq5uTtQ"
      },
      "source": [
        "Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEhtcBLxuYXX"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(0,len(y_train1)),output_data1[test_step:,1],label='Actual')\n",
        "plt.plot(np.arange(0,len(y_train1)),y_pred_trainset_inv[:,1] , label ='Predicted')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+SoZmiG3GYWjRdGM/TmHy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}